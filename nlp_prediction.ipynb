{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VwK5-9FIB-lu"
   },
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is a simple NLP prediction project, with Random Forest classification and XGBoost used as predictive models.  The data consists of hotel reviews, each giving a rating from 1 to 5, and I built the predictive model to make a guess as to what the given rating will be, based on the review.  It's more complex than a simple 0 or 1 binary prediction, and I like that.\n",
    "\n",
    "I've read people say that \"anyone can run xgboost with sklearn\" when talking about portfolio projects.  Well then I guess it's time to prove that I'm one of those \"anyone.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X1kiO9kACE6s"
   },
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QG7sxmoCIvN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\David\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Standard python libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#Libraries for NLP\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Libraries for Random Forest prediction model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import time\n",
    "\n",
    "#Libraries for XGBoost\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wTfaCIzdCLPA"
   },
   "source": [
    "## Read in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UCK6vQ5QCQJe"
   },
   "outputs": [],
   "source": [
    "#Read the dataset in\n",
    "reviews = pd.read_csv('tripadvisor_hotel_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  Rating\n",
      "0  nice hotel expensive parking got good deal sta...       4\n",
      "1  ok nothing special charge diamond member hilto...       2\n",
      "2  nice rooms not 4* experience hotel monaco seat...       3\n",
      "3  unique, great stay, wonderful time hotel monac...       5\n",
      "4  great stay great stay, went seahawk game aweso...       5\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20491 entries, 0 to 20490\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  20491 non-null  object\n",
      " 1   Rating  20491 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 320.3+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Print first several rows, examine dataframe specs\n",
    "print(dataset.head())\n",
    "print(\"\\n\")\n",
    "print(dataset.info())\n",
    "#Plot the ratings variable\n",
    "plt.hist(dataset['Rating'])\n",
    "plt.title('Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are no missing values in the dataframe, and looking at a histogram of the ratings, there aren't any outliers, although 5s are the most common rating.  There's no need to standardize the Ratings, because they're categorical. In addition, we don't need to encode the Ratings variable.\n",
    "\n",
    "The Descriptive MLR project in my portfolio requires some data cleaning, unlike this squeaky clean data.\n",
    "\n",
    "Now, let's take a look at the proportion of 5s in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of Ratings that are 5s: \n",
      "0.44\n"
     ]
    }
   ],
   "source": [
    "print(\"Proportion of Ratings that are 5s: \")\n",
    "print('{0:.2f}'.format((reviews['Rating'] == 5).sum()/len(reviews)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qekztq71CixT"
   },
   "source": [
    "## Clean the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following NLP cleaning, I remove characters, make each review lowercase, remove stopwords (such as I, you, we etc) that do not give any indication of positivity or negativity in predicting ratings, and stem each word.  \n",
    "\n",
    "What I did that isn't standard procedure is I left most negative words (not, didn't, wasn't, etc) in the dataset, because I think they're important for discerning meaning.  For example, \"Next summer, I will stay here,\" is a far different review from \"Next summer, I will not stay here.\"\n",
    "\n",
    "I'm going to add the NLP process to an import file eventually, but I wanted to walk you through it in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1977,
     "status": "ok",
     "timestamp": 1589837794372,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "8u_yXh9dCmEE",
    "outputId": "bdcb9868-74c8-40b2-e5e9-877b949ce385"
   },
   "outputs": [],
   "source": [
    "#NLP Cleaning\n",
    "corpus = []\n",
    "\n",
    "#The following for loop iterates through each review\n",
    "for i in range(0, len(reviews)): #20491\n",
    "  #remove everything that isn't a letter\n",
    "  message = re.sub('[^a-zA-Z]', ' ', reviews['Review'][i])\n",
    "  #remove uppercase letters\n",
    "  message = message.lower()\n",
    "  #Split message into comma-separated words\n",
    "  message = message.split()\n",
    "\n",
    "  #Load stopwords, remove most negatives because I think they'll be important\n",
    "  ps = PorterStemmer()\n",
    "  all_stopwords = stopwords.words('english')\n",
    "  for i in ['not', 'isn', 'wasn', 'won', 'shouldn', 'wouldn', 'weren', 'haven', \n",
    "            'hasn', 'hadn', 'aren', 'couldn', 'don', 'doesn', 'didn']:\n",
    "        all_stopwords.remove(i)\n",
    "  all_stopwords.append('got')\n",
    "\n",
    "  #Remove all stopwords from each message and stem the remaining words\n",
    "  message = [ps.stem(word) for word in message if not word in set(all_stopwords)]\n",
    "  #Put the message back together and add it to corpus\n",
    "  message = ' '.join(message)\n",
    "  corpus.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', \"aren't\", \"couldn't\", \"didn't\", \"doesn't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", \"shouldn't\", \"wasn't\", \"weren't\", \"won't\", \"wouldn't\", 'got']\n"
     ]
    }
   ],
   "source": [
    "#Print stopwords to see if any words need to be left in the dataset (can re-run the above if needed)\n",
    "print(all_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nice hotel expens park good deal stay hotel anniversari arriv late even took advic previou review valet park check quick easi littl disappoint non exist view room room clean nice size bed comfort woke stiff neck high pillow not soundproof like heard music room night morn loud bang door open close hear peopl talk hallway mayb noisi neighbor aveda bath product nice not goldfish stay nice touch taken advantag stay longer locat great walk distanc shop overal nice experi pay park night\n",
      "\n",
      "ok noth special charg diamond member hilton decid chain shot th anniversari seattl start book suit paid extra websit descript not suit bedroom bathroom standard hotel room took print reserv desk show said thing like tv couch ect desk clerk told oh mix suit descript kimpton websit sorri free breakfast kid embassi suit sit room bathroom bedroom unlik kimpton call suit day stay offer correct fals advertis send kimpton prefer guest websit email ask failur provid suit advertis websit reserv descript furnish hard copi reserv printout websit desk manag duti not repli solut send email trip guest survey not follow email mail guess tell concern guest staff rang indiffer not help ask desk good breakfast spot neighborhood hood told hotel gee best breakfast spot seattl block away conveni hotel not know exist arriv late night pm insid run bellman busi chate cell phone help bag prior arriv email hotel inform th anniversari half realli picki want make sure good nice email say like deliv bottl champagn chocol cover strawberri room arriv celebr told need foam pillow arriv champagn strawberri foam pillow great room view alley high rise build good not better housekeep staff cleaner room properti impress left morn shop room short trip hour bed comfort not good ac heat control x inch screen bring green shine directli eye night light sensit tape control not start hotel clean busi hotel super high rate better chain hotel seattl\n",
      "\n",
      "nice room not experi hotel monaco seattl good hotel n level posit larg bathroom mediterranean suit comfort bed pillowsattent housekeep staffneg ac unit malfunct stay desk disorgan miss separ wakeup call concierg busi hard touch n provid guidanc special request tv hard use ipod sound dock suit non function decid book mediterranean suit night weekend stay st choic rest parti fill comparison w spent night larger squar footag room great soak tub whirlpool jet nice shower stay hotel arrang car servic price tip reason driver wait arriv checkin easi downsid room pick person jacuzi tub bath accessori salt bubbl bath n stay night check voucher bottl champagn nice gestur fish wait room impress room huge open space felt room big tv far away bed chore chang channel ipod dock broken disappoint morn way ask desk check thermostat said f degre warm tri cover face night bright blue light kept room night st drop desk call maintain came look thermostat told play set happi digit box wo n work ask wakeup morn n happen call later pm nap wakeup forgot wakeup morn yep forgotten bathroom facil great room surpris room sold whirlpool bath tub n bath amen great relax water jet go\n"
     ]
    }
   ],
   "source": [
    "#Print the first few reviews' final form\n",
    "print(corpus[0] + \"\\n\\n\" + corpus[1] + \"\\n\\n\" + corpus[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CLqmAkANCp1-"
   },
   "source": [
    "## Create the Bag of Words Model/Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into the training set and the test set\n",
    "X = corpus\n",
    "y = dataset.iloc[:, -1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we split the data into the training set and the test set, fitting on training set and transforming it to a sparse matrix, but only transforming the test set to a sparse matrix, not fitting on the test set.  Fitting on the test set was a mistake I saw being made, even in online courses, so I wanted to mention it.\n",
    "\n",
    "A few parameters that can be tuned, which will have an effect on the accuracy of our prediction model, include the stopwords above, obviously, but also include the size of the training set vs test set, the max features of count vectorizer (that is, the number of words the model recognizes), the number of trees in the random forest model, and the random forest criterion.  I decided, for this model, to leave the test size at 20%, but I will run k-fold cross validation at the end.\n",
    "\n",
    "I wrote a function, rftuner, where you can enter a list of word counts, and a list of tree counts, as well as the criterion to try, which will print out the accuracy score and time of each attempt.  I've commented out the function call so that it doesn't take up your time unless you actually want to run it--there's an xgtuner as well.  Some of the tunings I've experimented with are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Varying the number of trees\n",
    "#words 2000, trees 100, .548\n",
    "#words 2000, trees 10, .506\n",
    "#words 2000, trees 1000, .559 <- highest\n",
    "\n",
    "#Varying the number of words\n",
    "#words 4000, trees 100, .546\n",
    "#words 3000, trees 100, .5459\n",
    "#words 1000, trees 100, .5508\n",
    "#words 1500, trees 100, .5528 <- highest\n",
    "#words 2500, trees 100, .5447\n",
    "\n",
    "#Varying the number of words using gini coefficient instead of entropy as the Random Forest Criterion\n",
    "#words 1500, trees 100, gini, .5557\n",
    "#words 1000, trees 100, gini, .5574\n",
    "#words 2000, trees 100, gini, .5472\n",
    "#words 750, trees 100, gini, .5618 <- highest\n",
    "#words 500, trees 100, gini, .5518\n",
    "\n",
    "#A couple more variations\n",
    "#words 750, trees 1000, gini, .5655 <- highest RF model I found\n",
    "#words 750, trees 100, entropy, .5455\n",
    "\n",
    "#XGBoost:\n",
    "#words 750, .595 <- highest model overall\n",
    "#words 500, .5816\n",
    "#words 1000, .593"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly enough, 750 words was the sweet spot.  Adding words intuitively seems like it would give the model more data to work with, but once the core words are obtained, extraneous words such as \"got\" are just going to get in the way of prediction accuracy.  The gini coefficient seemed to be a better criterion for this dataset than entropy, overall.  In addition, 100 trees is the sweet spot whenever I run random forest--1000 trees will add less than 1% accuracy here, but take many times longer to run.\n",
    "\n",
    "And of course, XGBoost ended up doing better than even Random Forest, which is no surprise.  It takes longer than 100-tree RF, but it's faster than 1000-tree RF, with better accuracy!  14 seconds for 100 trees, 123 seconds for 1000 trees, 95 seconds for XGBoost.\n",
    "\n",
    "The tuner functions are below so you can try variations yourself (just uncomment the function calls and modify the lists)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train: the original X training set, in reviews\n",
    "#rf_train: variable to store X_train within the rf loop\n",
    "#rf_train_loop: variable to modify rf_train in each iteration and then reread it, without changing the original\n",
    "#Same goes for y_train, rfy_train, xgy_train, xgy_train_loop, etc\n",
    "\n",
    "def rftuner(words = [20], trees = [10, 100], coeff = 'entropy', rfx_train = [[]], rfx_test = [[]], rfy_test = [[]], rfy_train = [[]]):\n",
    "    \"\"\"Run 1 or more Random Forest models on NLP training and test data.  It will iterate through the list of word counts,\n",
    "    and the list of trees, outputting the accuracy and time of each model.\n",
    "\n",
    "    Args:\n",
    "    words: list. A list of word counts to try for the bag of words model.\n",
    "    trees: list. A list of tree counts for the random forest model.\n",
    "    coeff: string. The criterion variable for the rf model.  Common choices are 'entropy' and 'gini' though others exist.\n",
    "    rfx_train: numpy array.  The training set of texts for the NLP model.\n",
    "    rfx_test: numpy array.  The test set of texts for the NLP model.\n",
    "    rfy_train: numpy array.  The training set of response variables to classify.\n",
    "    rfy_test: numpy array.  The test set of response variables measure predictions against.\n",
    "\n",
    "    Returns:\n",
    "    None.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    for i in words:\n",
    "        for j in trees:\n",
    "            #Create bag of words model/sparse matrix\n",
    "            cv = CountVectorizer(max_features = i)\n",
    "            rfx_train_loop = cv.fit_transform(rfx_train).toarray()\n",
    "            rfx_test_loop = cv.transform(rfx_test).toarray()\n",
    "            classifier = RandomForestClassifier(n_estimators = j, criterion = coeff, random_state = 0)\n",
    "            classifier.fit(rfx_train_loop, rfy_train)\n",
    "\n",
    "            #Make prediction vector\n",
    "            y_pred = classifier.predict(rfx_test_loop)\n",
    "            print('Random Forest ' + coeff + ' accuracy with ' + str(i) + ' words, ' + str(j) + ' trees: ' \n",
    "                  + '{0:.2f} %'.format(accuracy_score(rfy_test, y_pred)*100))\n",
    "            print('Time: ' + '{0:.2f}'.format(time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def xgtuner(words = [15], xgx_train = [[]], xgx_test = [[]], xgy_test = [[]], xgy_train = [[]]):\n",
    "    \"\"\"Run 1 or more XGBoost models on NLP training and test data.  It will iterate through the list of word counts, \n",
    "    outputting the accuracy and time of each model.\n",
    "\n",
    "    Args:\n",
    "    words: list. A list of word counts to try for the bag of words model.\n",
    "    xgx_train: numpy array.  The training set of texts for the NLP model.\n",
    "    xgx_test: numpy array.  The test set of texts for the NLP model.\n",
    "    xgy_train: numpy array.  The training set of response variables to classify.\n",
    "    xgy_test: numpy array.  The test set of response variables measure predictions against.\n",
    "\n",
    "    Returns:\n",
    "    None.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    for i in words:\n",
    "        #Create bag of words model/sparse matrix\n",
    "        cv = CountVectorizer(max_features = i)\n",
    "        xgx_train_loop = cv.fit_transform(xgx_train).toarray()\n",
    "        xgx_test_loop = cv.transform(xgx_test).toarray()\n",
    "        #XGBoost won't tolerate Ratings 1-5, so we turn them into 0-4:\n",
    "        xgy_train_loop = xgy_train.copy()\n",
    "        xgy_test_loop = xgy_test.copy()\n",
    "        for j in range(0, len(xgy_train_loop)):\n",
    "            xgy_train_loop[j] = xgy_train_loop[j] -1\n",
    "        for j in range(0, len(xgy_test_loop)):\n",
    "            xgy_test_loop[j] = xgy_test_loop[j] - 1\n",
    "        classifier = XGBClassifier()\n",
    "        classifier.fit(xgx_train_loop, xgy_train_loop)\n",
    "\n",
    "        #Make prediction vector\n",
    "        y_pred = classifier.predict(xgx_test_loop)\n",
    "        print('XGBoost ' + ' accuracy with ' + str(i) + ' words: ' \n",
    "              + '{0:.2f} %'.format(accuracy_score(xgy_test_loop, y_pred)*100))\n",
    "        print('Time: ' + '{0:.2f}'.format((time.time() - start_time)))\n",
    "        start_time = time.time()\n",
    "\n",
    "#uncomment the following line and adjust words list, trees list, and coeff if you want to try multiple runs\n",
    "#rftuner(words=[750], trees=[100, 1000], coeff='gini', rfx_train = X_train, rfx_test = X_test, rfy_test = y_test, rfy_train = y_train)\n",
    "        \n",
    "#uncomment the following line and adjust the words list if you want to try multiple runs    \n",
    "#xgtuner(words = [750], xgx_train = X_train, xgx_test = X_test, xgy_test = y_test, xgy_train = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll use the best model I found, the XGBoost model on 750 words, so that y_pred is available if we wanted to use it for something (remember to use y_pred + 1 if you ever use it against the original data).  I create final X_train, X_test, y_train, and y_test variables so that these cells can be continually rerun for experimentation, without having to reread the dataset above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VkIq23vEDIPt"
   },
   "source": [
    "## Training the selected model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create bag of words model/sparse matrix\n",
    "cv = CountVectorizer(max_features = 750)\n",
    "X_train_final = cv.fit_transform(X_train).toarray()\n",
    "X_test_final = cv.transform(X_test).toarray()\n",
    "\n",
    "#New variable names so I don't contaminate the originals\n",
    "y_train_final = y_train.copy()\n",
    "y_test_final = y_test.copy()\n",
    "\n",
    "#Modify Ratings to be 0-4 instead of 1-5, for XGBoost\n",
    "for i in range(0, len(y_train_final)):\n",
    "    y_train_final[i] = y_train_final[i] - 1\n",
    "for i in range(0, len(y_test_final)):\n",
    "    y_test_final[i] = y_test_final[i] - 1\n",
    "\n",
    "#Fit the model\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JaRM7zXDWUy"
   },
   "source": [
    "## Prediction Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4464,
     "status": "ok",
     "timestamp": 1589791461907,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "Iif0CVhFDaMp",
    "outputId": "1266c3f2-d500-440e-d756-e0eabad504a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [2 1]\n",
      " [4 3]\n",
      " ...\n",
      " [3 4]\n",
      " [3 3]\n",
      " [4 4]]\n"
     ]
    }
   ],
   "source": [
    "#Make prediction vector, compare it against y_test\n",
    "y_pred = classifier.predict(X_test_final)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test_final.reshape(len(y_test_final),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xoMltea5Dir1"
   },
   "source": [
    "## Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4462,
     "status": "ok",
     "timestamp": 1589791461907,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "Xj9IU6MxDnvo",
    "outputId": "43efba29-9811-4913-a085-8355ec1c02cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 188   57   11   11   18]\n",
      " [  79  107   61   65   43]\n",
      " [  12   79  101  212   67]\n",
      " [   3   20   66  575  539]\n",
      " [   2   10   11  294 1468]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.595023176384484"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make the confusion matrix and print the final accuracy score\n",
    "cm = confusion_matrix(y_test_final, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test_final, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty close!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Predictions\n",
    "#Adding 1 to y_pred and y_test_final to reflect the original Rating scale\n",
    "plt.hist(y_pred + 1, color='orange')\n",
    "plt.title('Predicted Ratings')\n",
    "plt.show()\n",
    "\n",
    "print('Pretty close!')\n",
    "\n",
    "#Plot Actual\n",
    "plt.hist(y_test_final + 1)\n",
    "plt.title('Actual Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross validation checks whether the model I selected can generalize across the entire dataset with similar accuracy,\n",
    "or if I simply got lucky because of the random training/test split that it landed on.  I commented it out so that you wouldn't have to sit through it for 20 minutes unless you want to.\n",
    "\n",
    "58.71% with standard deviation 1.19!  So our 59% accuracy is on the high end, but still feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold cross-validation\n",
    "#scores = cross_val_score(estimator = classifier, X = X_train_final, y = y_train_final, cv = 10)\n",
    "#print(\"Accuracy: {:.2f} %\".format(scores.mean()*100))\n",
    "#print(\"Standard Deviation: {:.2f} %\".format(scores.std()*100))\n",
    "\n",
    "#Accuracy: 58.71 %\n",
    "#Standard Deviation: 1.19 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm reasonably content with 59% accuracy, for a dataset with reviews optioned 1-5.  This isn't an accuracy score on a binary response variable; it's on 5 categories, and they're ambiguous as it is.  For example, someone might write a glowing 5-star review and then think \"there's always room for improvement\" and give a 4, or someone might write a scathing 1-star review and then feel a bit mean and give a 2, and so on.  And if the algorithm picks 4 and it was a 5, there's no measure here for that closeness to the mark.  That would be a good idea for a future program.\n",
    "\n",
    "Anyway, if you just guessed at each category, you should end up with about a 20% accuracy rate.  If you knew this dataset and knew that 5s were the most common at 44%, you could guess 5 for each one and get a 44% accuracy rate.  So, XGBoost getting 59% is something I'm ambivalent about--I'm pleased that something I implemented got this result, and yet I want it to be better.  It's coming..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMx/KsxUDrn2M5QbIb03B9p",
   "collapsed_sections": [],
   "name": "natural_language_processing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
